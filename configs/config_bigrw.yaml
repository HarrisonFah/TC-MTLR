dataset_name: big_rw
axis: 2  # For lambda baseline this has to be 1.
batch_size: 128
learning_rate: .01
log_interval: 1000
weight_decay: 1.e-2
num_epochs: 1000
output_file: Results/{}/
landmark: True
target_lr: .01
arch:
  type: transformer
  arch_kwargs:
    hidden_size: 16
    seq_len: 100  # Has to be the same as the horizon
    output_dim: 8
    num_layers: 1
    dropout: 0.2

preprocessed_data: False
dataset_kwargs:
  horizon: 100
  data_path: ../data/bigrw-seqs.pkl

lambda_: 0.0
num_steps: 5
verbose: True